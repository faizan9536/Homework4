{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **AML - Homework 4 Question 2**"
      ],
      "metadata": {
        "id": "1z3R8QEy31qU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80iYfPwQBo58"
      },
      "outputs": [],
      "source": [
        "# INSTALL THESE LIBRARIES IF NOT ALREADT INSTALLED\n",
        "\n",
        "# %%bash\n",
        "# pip install nltk\n",
        "# pip install datasets\n",
        "# pip install transformers[torch]\n",
        "# pip install tokenizers\n",
        "# pip install evaluate\n",
        "# pip install rouge_score\n",
        "# pip install sentencepiece\n",
        "# pip install huggingface_hub\n",
        "# pip install transformers datasets wandb accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b13bE-pICAmT"
      },
      "outputs": [],
      "source": [
        "# !pip install tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBo8PdzUCGBq"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers datasets wandb accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets"
      ],
      "metadata": {
        "id": "FWr_2Jy-sc7P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FmIcG7teCJLC"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from datasets import Dataset\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments,DataCollatorForSeq2Seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q1.**\n",
        "\n",
        "Pick an existing fine-tuning dataset (or create your own - you can create it by scraping the web or using some of the documents you have on your computer (do not use anything confidential or copyrighted) or by asking ChatGPT to generate the data). Mention which dataset you picked/created and briefly describe the dataset. [10 points]"
      ],
      "metadata": {
        "id": "B03cqw1z6YhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer**:\n",
        "\n",
        "For this task, our group chose the **\"yahoo_answers_qa\"** dataset from the datasets library in Python.\n",
        "\n",
        "This dataset is a comprehensive collection of question and answer pairs sourced from the Yahoo! Answers platform, covering diverse categories such as Society & Culture, Health, Science, and Technology. Each entry includes the question title, question content, best answer, and category.\n",
        "\n",
        "The datasets library, developed by Hugging Face, provides a simple and efficient way to load and process large datasets, making it a valuable tool for natural language processing tasks.\n",
        "\n",
        "Due to memory concerns, we used only 2% of the dataset, which still provides a rich and diverse set of examples. After selecting this subset, we split it into training and validation sets to use in the fine-tuning process. We did this to manage computational resources and avoid the memory run out error.\n",
        "\n",
        "The data is loaded in Q2."
      ],
      "metadata": {
        "id": "SWAgFWQu9DrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Link to our Wandb project report**\n",
        "\n",
        "https://api.wandb.ai/links/nsarwar-indiana-university/rwuur7jx\n"
      ],
      "metadata": {
        "id": "mLGVXamV9uf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q2.**\n",
        "\n",
        "Fine-tune an open-source pre-trained conversational language model of your choice (that you can take, e.g., from the Hugging Face Transformers library) with the dataset you picked or created. Make sure the model you pick has at least 500M parameters. [20 points]  Connect to wandb and to track the progress of your fine-tuning (e.g. your training loss). Share the link to your wandb project with us in the report you submit (see here for how to do it: https://wandb.ai/ivangoncharov/wandb-teams-for-students/reports/How-to-Use-W-B-Teams-For-Your-University-Machine-Learning-Projects-For-Free---VmlldzoxMjk1MjkxLinks to an external site.) [10 points] Test your model on a few prompts before and after fine-tunining and report any interesting differences. If you didn't observe any interesting differences, comment on why not. [10 points]"
      ],
      "metadata": {
        "id": "6rb7oe3A6hLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up wandb (it will ask for API to connect with wandb dashboard)"
      ],
      "metadata": {
        "id": "pv9CKSVn4HLI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "TUE_DX7zCKfF",
        "outputId": "37a6e09d-2b8f-4fc5-d1aa-929d1f5b2366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnsarwar\u001b[0m (\u001b[33mnsarwar-indiana-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241215_234425-mrarg9bl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nsarwar-indiana-university/flan-t5-fine-tuning/runs/mrarg9bl' target=\"_blank\">flan-t5-qa</a></strong> to <a href='https://wandb.ai/nsarwar-indiana-university/flan-t5-fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nsarwar-indiana-university/flan-t5-fine-tuning' target=\"_blank\">https://wandb.ai/nsarwar-indiana-university/flan-t5-fine-tuning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nsarwar-indiana-university/flan-t5-fine-tuning/runs/mrarg9bl' target=\"_blank\">https://wandb.ai/nsarwar-indiana-university/flan-t5-fine-tuning/runs/mrarg9bl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nsarwar-indiana-university/flan-t5-fine-tuning/runs/mrarg9bl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c62bd267550>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Step 2: Set up WandB for Experiment Tracking\n",
        "wandb.login()  # Login to WandB (you'll need an API key from your WandB account)\n",
        "wandb.init(project=\"flan-t5-fine-tuning\", name=\"flan-t5-qa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F3ZfXLdER1z"
      },
      "source": [
        "We chose the FLAN-T5 Model for this HW. Loading the FLAN-T5 Model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_vYYWVbQDjlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbab64fd-6a2b-4d0f-f8b5-7689202b0017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Load the Pre-Trained Model and Tokenizer\n",
        "MODEL_NAME = \"google/flan-t5-large\"  # Using Flan-T5 Large model (500M+ parameters)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eatx3HcNK2ao"
      },
      "source": [
        "Testing the model on different input prompts- Before Fine tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF1wQJdNK3jW",
        "outputId": "c014824b-5d10-4e1b-b486-298ef3098bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model before fine-tuning\n",
            "Input: Given the context of a 12-year-old attending middle school, answer the question: How old are you when you start high school?\n",
            "Output: 15\n",
            "Input: Answer the question: How can I solve my Python code problem?\n",
            "Output: Use a recursive method.\n",
            "Input: Answer the question: How can I print a hello world in java?\n",
            "Output: Use a java.split() function to print the hello world.\n",
            "Input: Based on common advice, how can someone effectively prepare for a job interview in the tech industry?\n",
            "Output: Prepare for the interview by reading the job description and preparing for the interview.\n",
            "Input: How can I prepare for a tech job interview?\n",
            "Output: You can use a resume and cover letter to impress the interviewer.\n",
            "Input: How to read a CSV file in Python using pandas?\n",
            "Output: csv = [int(x) for x in input().split()] csv.append(csv)\n",
            "Input: How to create a simple RESTful API in Python with Flask?\n",
            "Output: Using Flask, you can create a simple RESTful API in Python.\n"
          ]
        }
      ],
      "source": [
        "test_inputs = [\n",
        "    \"Given the context of a 12-year-old attending middle school, answer the question: How old are you when you start high school?\",\n",
        "    \"Answer the question: How can I solve my Python code problem?\",\n",
        "    \"Answer the question: How can I print a hello world in java?\",\n",
        "    \"Based on common advice, how can someone effectively prepare for a job interview in the tech industry?\",\n",
        "    \"How can I prepare for a tech job interview?\",\n",
        "    \"How to read a CSV file in Python using pandas?\",\n",
        "    \"How to create a simple RESTful API in Python with Flask?\"\n",
        "]\n",
        "\n",
        "print(\"Testing the model before fine-tuning\")\n",
        "for input_text in test_inputs:\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True).input_ids\n",
        "    outputs = model.generate(input_ids, max_length=50)\n",
        "    print(f\"Input: {input_text}\")\n",
        "    print(f\"Output: {tokenizer.decode(outputs[0], skip_special_tokens=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset \"yahoo_answers_qa\" to fine tune the model:"
      ],
      "metadata": {
        "id": "I3rjc5wR4eI4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7r6UuvMYEYSK"
      },
      "outputs": [],
      "source": [
        "\n",
        "DATA_NAME = \"yahoo_answers_qa\"\n",
        "stackoverflow_python = load_dataset(DATA_NAME, trust_remote_code=True)\n",
        "\n",
        "# The dataset is very large, I am reducing the size of training data\n",
        "\n",
        "shuffled_dataset = stackoverflow_python['train'].shuffle(seed=42)\n",
        "\n",
        "# Selecting 2% of the dataset\n",
        "num_samples = int(0.02 * len(shuffled_dataset))\n",
        "reduced_dataset = shuffled_dataset.select(range(num_samples))\n",
        "\n",
        "# Replacing the train dataset with the reduced dataset\n",
        "stackoverflow_python['train'] = reduced_dataset\n",
        "\n",
        "# dividing the dataset to train and test data\n",
        "stackoverflow_python = stackoverflow_python[\"train\"].train_test_split(test_size=0.3)\n",
        "\n",
        "stackoverflow_python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XvZgpRMaN-P1"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"question\"]\n",
        "    targets = examples[\"answer\"]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=512, truncation=True)\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICrQ8TXUNZ-z"
      },
      "source": [
        " tokenization of the dataset:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "6ac47280000644d68f14dc8d5864c761",
            "e93223985971427fb57a1151b1a23cfe",
            "eb6861c3396d4fc7be6bc59dfe15b6ca",
            "51a936fb27d8429991ccf32d85c19035",
            "7669a55263da478f8d126424211fdea9",
            "022ef76276ff4820bd2936cce513948d",
            "c296ebbbea204224a6bbac7aa21d1047",
            "5b1d5277cb6f45f6b06ce932bbce697c",
            "eb24c0ae39a94ccd85c358ba42ec8d3d",
            "f84b102e175e46699e7ee86e55753d93",
            "29bdcaaf32044187be2b11d1b68d8cf1",
            "618cc93cc71e44e4b27147de67728a63",
            "e145d1d9e3cd4ec0b3408f2d2f867d96",
            "9dfc5eca07f14b6eb0e232b17b724739",
            "0a57ec573a3f4daf90486283471b5f65",
            "3afb4e11e2b1462e8f28f2c8955f675e",
            "3ee93737ea0740049020cdb6118a4a4c",
            "f03e8875d81f40baab0ea78df1f7b11f",
            "0f0eb58656d245e1b36695ff405e4d96",
            "da49ab028775442dbf0907dc17df8ec6",
            "5d420de5a1594f25af91aebfbfe22efe",
            "bac5a4fab6884aebb076ec0e1dfb7505"
          ]
        },
        "id": "2gWT8m_BNbRD",
        "outputId": "a58d4cc8-7143-4026-cf56-a329b8b3ed52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1222 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ac47280000644d68f14dc8d5864c761"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/525 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "618cc93cc71e44e4b27147de67728a63"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_dataset = stackoverflow_python.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_6lZXkHOw0j"
      },
      "source": [
        "preparing data collator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FgTHq84rOvpd"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAokbanRL6fW"
      },
      "source": [
        "**Fine- tunning the model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhslrzn7L8kF",
        "outputId": "de5d2f8c-4287-4876-ac85-3afaf28c1ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./flan-t5-finetuned\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    # fp16=True,\n",
        "    bf16=True,\n",
        "    report_to=\"wandb\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlyt5ejnPgv8"
      },
      "source": [
        "**Defining the Trainer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qP55AgxO4eb",
        "outputId": "6114b1d7-f2b8-4cb0-9a63-ebfb26efe162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a38181dec01a>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,                         # Pre-trained model\n",
        "    args=training_args,                  # Training arguments\n",
        "    train_dataset=tokenized_dataset[\"train\"],     # Tokenized training dataset\n",
        "    eval_dataset=tokenized_dataset[\"test\"],      # Tokenized evaluation dataset\n",
        "    tokenizer=tokenizer,                 # Tokenizer\n",
        "    data_collator=data_collator          # Handles padding dynamically\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring that both the model and inputs are stored on gpu (same device):"
      ],
      "metadata": {
        "id": "n8s6fkdl5Y4c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2-xY-pKRm2F",
        "outputId": "e333fb9b-a842-4404-eaee-9d1ee64e24b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 1024)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 1024)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 16)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-23): 23 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 1024)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 16)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-23): 23 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Explicitly set the device to CPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Move the model to CPU\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model on yahoo dataset (with the specified parameters in training_args earlier) :**"
      ],
      "metadata": {
        "id": "pmljUgT55hfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "GQJXly7QO9PG",
        "outputId": "ccb893b2-56bc-49f5-d5fd-611f9c752988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1520' max='1520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1520/1520 32:53, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.212700</td>\n",
              "      <td>3.039998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.992600</td>\n",
              "      <td>3.035279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.862400</td>\n",
              "      <td>3.039718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.739900</td>\n",
              "      <td>3.051322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.613100</td>\n",
              "      <td>3.065259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.544600</td>\n",
              "      <td>3.085451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.501900</td>\n",
              "      <td>3.096652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.419800</td>\n",
              "      <td>3.109341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.406900</td>\n",
              "      <td>3.117339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.370500</td>\n",
              "      <td>3.120727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1520, training_loss=2.665618361924824, metrics={'train_runtime': 1977.0819, 'train_samples_per_second': 6.181, 'train_steps_per_second': 0.769, 'total_flos': 978202938138624.0, 'train_loss': 2.665618361924824, 'epoch': 9.965630114566284})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loss is decreasing. However the validation loss keeps increasing a little. The reason could be a very small training dataset. Due to memory issues we have kept the training data to minimum size."
      ],
      "metadata": {
        "id": "V79_yATS5xVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpUxilTxPBLe",
        "outputId": "4db48dd2-558b-43d6-e91b-44be328c1fa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./flan-t5-finetuned/tokenizer_config.json',\n",
              " './flan-t5-finetuned/special_tokens_map.json',\n",
              " './flan-t5-finetuned/spiece.model',\n",
              " './flan-t5-finetuned/added_tokens.json',\n",
              " './flan-t5-finetuned/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#Save the Fine-Tuned Model\n",
        "model.save_pretrained(\"./flan-t5-finetuned\")\n",
        "tokenizer.save_pretrained(\"./flan-t5-finetuned\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOkSgw-oPF08"
      },
      "source": [
        "**Testing the Model with same input prompts After Fine-Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naEBgCg2PCUX",
        "outputId": "316cbf9b-97aa-429a-c92a-7da84433ab8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the  model after fine-tuning\n",
            "Input: Given the context of a 12-year-old attending middle school, answer the question: How old are you when you start high school?\n",
            "Output: You will be 13 years old when you start high school.\n",
            "Input: Answer the question: How can I solve my Python code problem?\n",
            "Output: if you are using a python interpreter, you can use a python interpreter to compile your code. . . if you are using a python\n",
            "Input: Answer the question: How can I print a hello world in java?\n",
            "Output: if you are using java 1.6 or higher you can use javascript.split(\" \") to print the hello world. . . if you are using java 1.8 or higher you can use\n",
            "Input: Based on common advice, how can someone effectively prepare for a job interview in the tech industry?\n",
            "Output: You'll need to know what you're talking about. You'll also need to know what you're talking about. You'll need to know what you're talking about.\n",
            "Input: How can I prepare for a tech job interview?\n",
            "Output: You can't prepare for a job interview without knowing what you're talking about. You'll need to know what you're talking about, what you're going to say, and what you're going to say in\n",
            "Input: How to read a CSV file in Python using pandas?\n",
            "Output: if you are using python3 you can use sys.stdin.readline().split() to read the csv file. . . . . \n",
            "Input: How to create a simple RESTful API in Python with Flask?\n",
            "Output: Using a simple GET request and a GET response. Using a GET result and a GET response.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTesting the  model after fine-tuning\")\n",
        "fine_tuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"./flan-t5-finetuned\")\n",
        "fine_tuned_tokenizer = AutoTokenizer.from_pretrained(\"./flan-t5-finetuned\")\n",
        "\n",
        "for input_text in test_inputs:\n",
        "    input_ids = fine_tuned_tokenizer(input_text, return_tensors=\"pt\", truncation=True).input_ids\n",
        "    outputs = fine_tuned_model.generate(input_ids, max_length=50)\n",
        "    print(f\"Input: {input_text}\")\n",
        "    print(f\"Output: {fine_tuned_tokenizer.decode(outputs[0], skip_special_tokens=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Thoughts and Discussion**\n",
        "\n",
        "* We chose **google/flan-t5-large** pre trained model, which has 780 million parameters.\n",
        "\n",
        "* **Link to wandb project:**\n",
        "\n",
        "https://api.wandb.ai/links/nsarwar-indiana-university/rwuur7jx\n"
      ],
      "metadata": {
        "id": "WQR3SP8I6OHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Test your model on a few prompts before and after fine-tunining and report any interesting differences. If you didn't observe any interesting differences, comment on why not. [10 points]\n",
        "\n",
        "We have tested the model on different input prompts before and after tunning (shown above in code).\n",
        "\n",
        "**Insights on the fine tuned model**\n",
        "After fine-tuning, the model provided more detailed but often repetitive and less coherent responses. The increased wordiness and repetition suggest overfitting on the smaller dataset, indicating a need for further fine-tuning or data augmentation. This was expected because our training dataset was very small.  \n",
        "\n",
        "Before fine-tuning, the model provided brief and sometimes inaccurate responses. After fine-tuning, the model's responses were more detailed but often contained repetition or incomplete sentences. This could indicate that the model started to overfit on the smaller dataset, learning patterns specific to it but losing some generalization capability. The increase in wordiness also suggest that the model tried to provide more context but struggled with coherency, pointing to the need for further fine-tuning or data augmentation to achieve better performance.\n"
      ],
      "metadata": {
        "id": "jre1EXUC-H0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### END of Homework 4 Question 2\n",
        "\n",
        "--------------"
      ],
      "metadata": {
        "id": "ptfaneKHEPDa"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ac47280000644d68f14dc8d5864c761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e93223985971427fb57a1151b1a23cfe",
              "IPY_MODEL_eb6861c3396d4fc7be6bc59dfe15b6ca",
              "IPY_MODEL_51a936fb27d8429991ccf32d85c19035"
            ],
            "layout": "IPY_MODEL_7669a55263da478f8d126424211fdea9"
          }
        },
        "e93223985971427fb57a1151b1a23cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022ef76276ff4820bd2936cce513948d",
            "placeholder": "​",
            "style": "IPY_MODEL_c296ebbbea204224a6bbac7aa21d1047",
            "value": "Map: 100%"
          }
        },
        "eb6861c3396d4fc7be6bc59dfe15b6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1d5277cb6f45f6b06ce932bbce697c",
            "max": 1222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb24c0ae39a94ccd85c358ba42ec8d3d",
            "value": 1222
          }
        },
        "51a936fb27d8429991ccf32d85c19035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84b102e175e46699e7ee86e55753d93",
            "placeholder": "​",
            "style": "IPY_MODEL_29bdcaaf32044187be2b11d1b68d8cf1",
            "value": " 1222/1222 [00:00&lt;00:00, 7413.88 examples/s]"
          }
        },
        "7669a55263da478f8d126424211fdea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022ef76276ff4820bd2936cce513948d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c296ebbbea204224a6bbac7aa21d1047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b1d5277cb6f45f6b06ce932bbce697c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb24c0ae39a94ccd85c358ba42ec8d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84b102e175e46699e7ee86e55753d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29bdcaaf32044187be2b11d1b68d8cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "618cc93cc71e44e4b27147de67728a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e145d1d9e3cd4ec0b3408f2d2f867d96",
              "IPY_MODEL_9dfc5eca07f14b6eb0e232b17b724739",
              "IPY_MODEL_0a57ec573a3f4daf90486283471b5f65"
            ],
            "layout": "IPY_MODEL_3afb4e11e2b1462e8f28f2c8955f675e"
          }
        },
        "e145d1d9e3cd4ec0b3408f2d2f867d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee93737ea0740049020cdb6118a4a4c",
            "placeholder": "​",
            "style": "IPY_MODEL_f03e8875d81f40baab0ea78df1f7b11f",
            "value": "Map: 100%"
          }
        },
        "9dfc5eca07f14b6eb0e232b17b724739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0eb58656d245e1b36695ff405e4d96",
            "max": 525,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da49ab028775442dbf0907dc17df8ec6",
            "value": 525
          }
        },
        "0a57ec573a3f4daf90486283471b5f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d420de5a1594f25af91aebfbfe22efe",
            "placeholder": "​",
            "style": "IPY_MODEL_bac5a4fab6884aebb076ec0e1dfb7505",
            "value": " 525/525 [00:00&lt;00:00, 7809.98 examples/s]"
          }
        },
        "3afb4e11e2b1462e8f28f2c8955f675e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee93737ea0740049020cdb6118a4a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03e8875d81f40baab0ea78df1f7b11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f0eb58656d245e1b36695ff405e4d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da49ab028775442dbf0907dc17df8ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d420de5a1594f25af91aebfbfe22efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bac5a4fab6884aebb076ec0e1dfb7505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}